{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfconvmnist.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pyhFpQzth_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "%matplotlib inline\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5p-TJ_KtnMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "13348a64-e989-4c32-bb15-755984550d88"
      },
      "source": [
        "data = input_data.read_data_sets('data/fashion',one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0812 22:14:10.688393 140358724282240 deprecation.py:323] From <ipython-input-2-c16302e8c919>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0812 22:14:10.693334 140358724282240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0812 22:14:10.695672 140358724282240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0812 22:14:10.799438 140358724282240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting data/fashion/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0812 22:14:11.066027 140358724282240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0812 22:14:11.068745 140358724282240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0812 22:14:11.147722 140358724282240 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_-Cm9mTtvYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7e58289b-a215-4d98-e17e-c8d34aa3a49a"
      },
      "source": [
        "data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fa78572dfd0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fa78572ddd8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fa7777ec860>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vy8uLEXtxKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "521b3b56-af6b-4681-e437-d2aff49e7b02"
      },
      "source": [
        "# Shapes of training set\n",
        "print(\"Training set (images) shape: {shape}\".format(shape=data.train.images.shape))\n",
        "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
        "\n",
        "# Shapes of test set\n",
        "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
        "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (images) shape: (55000, 784)\n",
            "Training set (labels) shape: (55000, 10)\n",
            "Test set (images) shape: (10000, 784)\n",
            "Test set (labels) shape: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3b_KNR_t17a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {\n",
        " 0: 'T-shirt/top',\n",
        " 1: 'Trouser',\n",
        " 2: 'Pullover',\n",
        " 3: 'Dress',\n",
        " 4: 'Coat',\n",
        " 5: 'Sandal',\n",
        " 6: 'Shirt',\n",
        " 7: 'Sneaker',\n",
        " 8: 'Bag',\n",
        " 9: 'Ankle boot',\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dda4bMgruBR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4a6d061a-4187-4b85-dbcc-d4a16bf8ec20"
      },
      "source": [
        "plt.figure(figsize=[5,5])\n",
        "\n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "curr_img = np.reshape(data.train.images[0], (28,28))\n",
        "curr_lbl = np.argmax(data.train.labels[0,:])\n",
        "plt.imshow(curr_img, cmap='gray')\n",
        "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
        "\n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "curr_img = np.reshape(data.test.images[0], (28,28))\n",
        "curr_lbl = np.argmax(data.test.labels[0,:])\n",
        "plt.imshow(curr_img, cmap='gray')\n",
        "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '(Label: Sneaker)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAACuCAYAAACr3LH6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw612AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZKch_TjuGnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = data.train.images.reshape(-1, 28, 28, 1)\n",
        "test_X = data.test.images.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbRw8rE2ubrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = data.train.labels\n",
        "test_y = data.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2orJIF6ugwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_iters = 200 \n",
        "learning_rate = 0.001 \n",
        "batch_size = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvRiBpQdunoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST data input (img shape: 28*28)\n",
        "n_input = 28\n",
        "\n",
        "# MNIST total classes (0-9 digits)\n",
        "n_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjsZHXXvux6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#both placeholders are of type float\n",
        "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIpxehemu4m6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x) \n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clRXD2MDvLXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "}\n",
        "biases = {\n",
        "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YCfgjA0vSjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_net(x, weights, biases):  \n",
        "\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
        "    conv3 = maxpool2d(conv3, k=2)\n",
        "\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Output, class prediction\n",
        "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2jmjkkRvmqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2c24fe57-b35d-416f-cf77-ab599537b3bb"
      },
      "source": [
        "pred = conv_net(x, weights, biases)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0812 22:22:35.368891 140358724282240 deprecation.py:323] From <ipython-input-15-989f812044df>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BJENpfwvql6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "\n",
        "#calculate accuracy across all the given images and average them out. \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heWpsFt6vu5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTpf-0mcvyEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "219e24c2-dfc9-492d-8278-e3174d1df9f0"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(init) \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    for i in range(training_iters):\n",
        "        for batch in range(len(train_X)//batch_size):\n",
        "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
        "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
        "            # Run optimization op (backprop).\n",
        "                # Calculate batch loss and accuracy\n",
        "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
        "                                                              y: batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
        "                                                              y: batch_y})\n",
        "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
        "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                      \"{:.5f}\".format(acc))\n",
        "        print(\"Optimization Finished!\")\n",
        "\n",
        "        # Calculate accuracy for all 10000 mnist test images\n",
        "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
        "        train_loss.append(loss)\n",
        "        test_loss.append(valid_loss)\n",
        "        train_accuracy.append(acc)\n",
        "        test_accuracy.append(test_acc)\n",
        "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
        "    summary_writer.close()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0, Loss= 0.135224, Training Accuracy= 0.96484\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.90270\n",
            "Iter 1, Loss= 0.053765, Training Accuracy= 0.98730\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.95800\n",
            "Iter 2, Loss= 0.033143, Training Accuracy= 0.98926\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.97180\n",
            "Iter 3, Loss= 0.023638, Training Accuracy= 0.99316\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.97620\n",
            "Iter 4, Loss= 0.023299, Training Accuracy= 0.99316\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.97560\n",
            "Iter 5, Loss= 0.016058, Training Accuracy= 0.99414\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98120\n",
            "Iter 6, Loss= 0.012999, Training Accuracy= 0.99609\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98370\n",
            "Iter 7, Loss= 0.010124, Training Accuracy= 0.99805\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98540\n",
            "Iter 8, Loss= 0.009782, Training Accuracy= 0.99609\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98550\n",
            "Iter 9, Loss= 0.010074, Training Accuracy= 0.99512\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98490\n",
            "Iter 10, Loss= 0.010744, Training Accuracy= 0.99414\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98380\n",
            "Iter 11, Loss= 0.009094, Training Accuracy= 0.99707\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98590\n",
            "Iter 12, Loss= 0.005379, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98930\n",
            "Iter 13, Loss= 0.003406, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98870\n",
            "Iter 14, Loss= 0.002994, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98980\n",
            "Iter 15, Loss= 0.003438, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99010\n",
            "Iter 16, Loss= 0.003440, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98880\n",
            "Iter 17, Loss= 0.003957, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98730\n",
            "Iter 18, Loss= 0.003874, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98690\n",
            "Iter 19, Loss= 0.003066, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98850\n",
            "Iter 20, Loss= 0.002951, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98900\n",
            "Iter 21, Loss= 0.002410, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98900\n",
            "Iter 22, Loss= 0.001880, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98980\n",
            "Iter 23, Loss= 0.001685, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99000\n",
            "Iter 24, Loss= 0.002541, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99050\n",
            "Iter 25, Loss= 0.001586, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98790\n",
            "Iter 26, Loss= 0.001878, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98820\n",
            "Iter 27, Loss= 0.000727, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99110\n",
            "Iter 28, Loss= 0.000842, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99010\n",
            "Iter 29, Loss= 0.001371, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98940\n",
            "Iter 30, Loss= 0.001143, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99010\n",
            "Iter 31, Loss= 0.002355, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98860\n",
            "Iter 32, Loss= 0.001422, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99040\n",
            "Iter 33, Loss= 0.002262, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98970\n",
            "Iter 34, Loss= 0.000507, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99070\n",
            "Iter 35, Loss= 0.000280, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98860\n",
            "Iter 36, Loss= 0.000350, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99000\n",
            "Iter 37, Loss= 0.000257, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98900\n",
            "Iter 38, Loss= 0.000458, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98870\n",
            "Iter 39, Loss= 0.000277, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99120\n",
            "Iter 40, Loss= 0.000470, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99030\n",
            "Iter 41, Loss= 0.000390, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99140\n",
            "Iter 42, Loss= 0.000501, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99180\n",
            "Iter 43, Loss= 0.000236, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 44, Loss= 0.000249, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99150\n",
            "Iter 45, Loss= 0.000739, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98960\n",
            "Iter 46, Loss= 0.000339, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98910\n",
            "Iter 47, Loss= 0.000109, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99210\n",
            "Iter 48, Loss= 0.000118, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99080\n",
            "Iter 49, Loss= 0.000316, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99090\n",
            "Iter 50, Loss= 0.000174, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99150\n",
            "Iter 51, Loss= 0.001597, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99010\n",
            "Iter 52, Loss= 0.000697, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98920\n",
            "Iter 53, Loss= 0.000326, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99020\n",
            "Iter 54, Loss= 0.000601, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99120\n",
            "Iter 55, Loss= 0.000654, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99210\n",
            "Iter 56, Loss= 0.000409, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99060\n",
            "Iter 57, Loss= 0.000395, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99120\n",
            "Iter 58, Loss= 0.000187, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99180\n",
            "Iter 59, Loss= 0.000267, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99080\n",
            "Iter 60, Loss= 0.000136, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99130\n",
            "Iter 61, Loss= 0.000399, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99170\n",
            "Iter 62, Loss= 0.000771, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99040\n",
            "Iter 63, Loss= 0.003052, Training Accuracy= 0.99902\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98840\n",
            "Iter 64, Loss= 0.000088, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98930\n",
            "Iter 65, Loss= 0.001303, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99060\n",
            "Iter 66, Loss= 0.001003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99020\n",
            "Iter 67, Loss= 0.000624, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.98920\n",
            "Iter 68, Loss= 0.000144, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99120\n",
            "Iter 69, Loss= 0.000104, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99090\n",
            "Iter 70, Loss= 0.000215, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99180\n",
            "Iter 71, Loss= 0.000182, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99110\n",
            "Iter 72, Loss= 0.000189, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99190\n",
            "Iter 73, Loss= 0.000436, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99180\n",
            "Iter 74, Loss= 0.000030, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99200\n",
            "Iter 75, Loss= 0.000023, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 76, Loss= 0.000015, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 77, Loss= 0.000012, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 78, Loss= 0.000011, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 79, Loss= 0.000010, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 80, Loss= 0.000012, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 81, Loss= 0.000010, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 82, Loss= 0.000009, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 83, Loss= 0.000017, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 84, Loss= 0.000026, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 85, Loss= 0.000033, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 86, Loss= 0.000038, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 87, Loss= 0.000036, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 88, Loss= 0.000031, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 89, Loss= 0.000027, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 90, Loss= 0.000023, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 91, Loss= 0.000021, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 92, Loss= 0.000019, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 93, Loss= 0.000017, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99220\n",
            "Iter 94, Loss= 0.000016, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 95, Loss= 0.000014, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 96, Loss= 0.000013, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 97, Loss= 0.000012, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 98, Loss= 0.000011, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 99, Loss= 0.000011, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 100, Loss= 0.000010, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 101, Loss= 0.000009, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 102, Loss= 0.000009, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 103, Loss= 0.000008, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 104, Loss= 0.000008, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 105, Loss= 0.000007, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 106, Loss= 0.000007, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 107, Loss= 0.000007, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 108, Loss= 0.000007, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 109, Loss= 0.000006, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 110, Loss= 0.000006, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 111, Loss= 0.000006, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 112, Loss= 0.000006, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 113, Loss= 0.000005, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 114, Loss= 0.000005, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 115, Loss= 0.000005, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 116, Loss= 0.000005, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 117, Loss= 0.000005, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 118, Loss= 0.000004, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 119, Loss= 0.000004, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 120, Loss= 0.000004, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 121, Loss= 0.000004, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 122, Loss= 0.000004, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 123, Loss= 0.000004, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 124, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 125, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 126, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 127, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 128, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 129, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 130, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 131, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 132, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 133, Loss= 0.000003, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 134, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 135, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99230\n",
            "Iter 136, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 137, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 138, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 139, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 140, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 141, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 142, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 143, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 144, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 145, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 146, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 147, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 148, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 149, Loss= 0.000002, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 150, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 151, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 152, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 153, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 154, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 155, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 156, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 157, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 158, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 159, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 160, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 161, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 162, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 163, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 164, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 165, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 166, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 167, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 168, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 169, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 170, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 171, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 172, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 173, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 174, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 175, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 176, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 177, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 178, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 179, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 180, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 181, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 182, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 183, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 184, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 185, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 186, Loss= 0.000001, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 187, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 188, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 189, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 190, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 191, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99250\n",
            "Iter 192, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 193, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 194, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 195, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 196, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 197, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 198, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n",
            "Iter 199, Loss= 0.000000, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.99240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpOQfvrVv38J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAWnAgraw3nr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "6b280ab3-2043-4e39-b033-6f5e5f2158ea"
      },
      "source": [
        "plt.plot(range(len(train_loss)), train_loss, 'b', label='Training loss')\n",
        "plt.plot(range(len(train_loss)), test_loss, 'r', label='Test loss')\n",
        "plt.title('Training and Test loss')\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEbCAYAAAD0yNLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOXZ//HPRQIEBNkVBVlEXIKW\nxRS0uEvdKz4ulSpqRaW2Lm2tVmx9XLC/ij5P1dbiQi2uKGKtlvqg4L7UKiCiCIosWg07QdkFk1y/\nP+4TMoQ5k2SSzAzwfb9e85o525wrJ8m55rrvM+c2d0dERKS2GmU7ABER2T4pgYiISFqUQEREJC1K\nICIikhYlEBERSYsSiIiIpEUJRLZrZpZnZuvMrEt9rptNZraPmeXU9fVmdqCZfZPtOCS3KIFIRkUn\n8IpHuZltTJg+t7bv5+5l7t7C3b+oz3VzUUICjDt+Z9fhvaeb2ZD6jFd2fPnZDkB2Lu7eouK1mX0O\nXOzuL8Wtb2b57l6aidhynbuXAYnHrxgY6u6vZS0o2ampApGcYma/M7MnzewJM1sLDDWzQ83sHTP7\n2syWmNmfzKxxtH6+mbmZdYumH4uWP29ma83s32bWvbbrRstPNLNPzWy1md1tZv8ysx/HxF2TGH9i\nZvPN7Csz+1PCtnlmdqeZlZjZQuCEOhy/fDO7ycw+M7OVZvaome0aLWthZhPMbFUUwztm1srM7gL6\nAg9FlcxtNdhP1+i4fWVmc81saMKyw81sppmtiY7F71LtP92fVbJPCURy0X8BjwOtgCeBUuDnQHtg\nIOEE+5MU258D/DfQFvgCuKW265rZbsAE4Jpov58B/VO8T01iPAk4mHCyHmpmg6L5PwWOA3oD3wV+\nmGI/1bkWOAo4FNgrmveH6PkngAN7Ah2AK4HN7v4L4H3gx1ET37WpdmBmBjwNzAY6AucBd5vZgGiV\ne4Cb3X1XYD9gYqr91+FnlSxTApFc9Ja7/9Pdy919o7tPc/d33b3U3RcCY4AjU2z/N3ef7u7fAuOA\nPmmsewow093/ES27E1gZ9yY1jPFWd1/t7p8DryXs64fAne5e7O4lwKgU8VbnUuBad1/q7huBkUBF\n38a3hBP33lGcU6N1amt/oBC43t03uftU4DFCIqnYz75m1tbd10TL63P/kiOUQCQXfZk4YWb7m9n/\nmdlSM1tDOCm2T7H90oTXG0joN6jFunsmxuHhrqPFcW9SwxhrtC/gPynijWVmeUAnYErUlPY1MA1o\nbGatCUntbeAZM/syai5M5xywJ7DM3ROvyvpPtG8IiaQImBc1U30/ml9f+5ccoV+e5KKql7DeD3wE\n7BM1i9wAWAPHsAToXDERNdt0il+9TjEuobK5CSCty4yjTvYlwBHu3jrhUeDuX7v7N+5+vbvvBxxN\naL47q2LzWuxqMbC7mTWtEvOiKI7Z7n4WsBtwL/D36GKIVPuX7ZASiGwPWgKrgfVmdgCp+z/qy3NA\nPzP7gZnlE/o3OjRQjBOAX5hZJzNrR+jHSNd9wG1m1gnAzHY3s1Oi1983swOiT/1rCP025dF2y4C9\na7iPT6LHLWbWxMyKgKGEJkDM7Pyo+aqMcEzKAa9m/7IdUgKR7cGvgAuAtYRP+k829A7dfRlwNnAH\nUAL0IHQ0b2qAGO8FXgZmEZqc/pZe1ADcCrwBvB41pb1F6LSHUOX8M4rxA+AfhM5wCB3tF0VNX7em\n2kHUnHcGodN/GeGCh1+6+7+jVQYDn1q4iu5m4OwomaTav2yHTANKiVQv6l9YDJzp7m9mOx6RXKAK\nRCSGmZ1gZq2jtv7/JlxFNLWazUR2GkogIvEOAxYCK4Djgf9y97gmLJGdjpqwREQkLapAREQkLTv0\nzRTbt2/v3bp1y3YYIiLblffee2+lu6e6bB3YwRNIt27dmD59erbDEBHZrphZje6GoCYsERFJixKI\niIikRQlERETSskP3gYhIbvr2228pLi7mm280zHo2FRQU0LlzZxo3bpzW9kogIpJxxcXFtGzZkm7d\nuhFudCyZ5u6UlJRQXFxM9+7dq98gCTVhiUjGffPNN7Rr107JI4vMjHbt2tWpClQCEZGsUPLIvrr+\nDpRAklm3Dm64AabqvnkiInGUQJLZuBFuuQWmTct2JCLSAEpKSujTpw99+vShY8eOdOrUacv05s2b\na/QeF154IXPnzk25zujRoxk3blx9hMxhhx3GzJkz6+W96os60ZPJywvPpaXZjUNEGkS7du22nIxv\nuukmWrRowdVXX73VOu6Ou9OoUfLP2Q8++GC1+7nsssvqHmwOUwWSTH6UV8vKshuHiGTU/PnzKSws\n5Nxzz6VXr14sWbKE4cOHU1RURK9evRg5cuSWdSsqgtLSUlq3bs2IESPo3bs3hx56KMuXLwfg+uuv\n56677tqy/ogRI+jfvz/77bcfb7/9NgDr16/njDPOoLCwkDPPPJOioqJqK43HHnuMgw46iAMPPJDf\n/OY3AJSWlnLeeedtmf+nP/0JgDvvvJPCwkK+853vMHTo0Ho9XqpAklEFIpIxv/gF1HfLTJ8+EJ23\na+2TTz7hkUceoaioCIBRo0bRtm1bSktLOfrooznzzDMpLCzcapvVq1dz5JFHMmrUKK666irGjh3L\niBEjtnlvd2fq1KlMnDiRkSNH8sILL3D33XfTsWNHnn76aT744AP69euXMr7i4mKuv/56pk+fTqtW\nrRg0aBDPPfccHTp0YOXKlcyaNQuAr7/+GoDbb7+d//znPzRp0mTLvPqiCiQZVSAiO60ePXpsSR4A\nTzzxBP369aNfv358/PHHzJkzZ5ttmjVrxoknngjAwQcfzOeff570vU8//fRt1nnrrbcYMmQIAL17\n96ZXr14p43v33Xc55phjaN++PY0bN+acc87hjTfeYJ999mHu3LlceeWVTJ48mVatWgHQq1cvhg4d\nyrhx49L+wmAcVSDJqAIRyZh0K4WGsssuu2x5PW/ePP74xz8ydepUWrduzdChQ5N+b6JJkyZbXufl\n5VEac+5o2rRpteukq127dnz44Yc8//zzjB49mqeffpoxY8YwefJkXn/9dSZOnMjvf/97PvzwQ/Iq\nznF1pAokmYqDqwpEZKe2Zs0aWrZsya677sqSJUuYPHlyve9j4MCBTJgwAYBZs2YlrXASDRgwgFdf\nfZWSkhJKS0sZP348Rx55JCtWrMDdOeussxg5ciQzZsygrKyM4uJijjnmGG6//XZWrlzJhg0b6i12\nVSDJmEGjRqpARHZy/fr1o7CwkP3335+uXbsycODAet/HFVdcwfnnn09hYeGWR0XzUzKdO3fmlltu\n4aijjsLd+cEPfsDJJ5/MjBkzuOiii3B3zIzbbruN0tJSzjnnHNauXUt5eTlXX301LVu2rLfYd+gx\n0YuKijztAaWaNoWrroJbb63foESEjz/+mAMOOCDbYeSE0tJSSktLKSgoYN68eRx33HHMmzeP/PzM\nfL5P9rsws/fcvShmky1UgcTJy1MFIiINbt26dRx77LGUlpbi7tx///0ZSx51tX1EmQ35+eoDEZEG\n17p1a957771sh5GWjHeim9kJZjbXzOab2TYXSpvZpWY2y8xmmtlbZlaYsOy6aLu5ZnZ8gwaqCkRE\nJKWMJhAzywNGAycChcCPEhNE5HF3P8jd+wC3A3dE2xYCQ4BewAnAPdH7NQxVICIiKWW6AukPzHf3\nhe6+GRgPDE5cwd3XJEzuAlT08g8Gxrv7Jnf/DJgfvV/DUAUiIpJSpvtAOgFfJkwXAwOqrmRmlwFX\nAU2AYxK2fafKtp2SbDscGA7QpUuX9CNVBSIiklJOfpHQ3Ue7ew/gWuD6Wm47xt2L3L2oQ4cO6Qeh\nCkRkh1Uft3MHGDt2LEuXLk26bOjQoTz77LP1FXJOynQFsgjYK2G6czQvznjg3jS3rRtVICI7rJrc\nzr0mxo4dS79+/ejYsWN9h7hdyHQFMg3oaWbdzawJoVN8YuIKZtYzYfJkYF70eiIwxMyamll3oCfQ\ncEMGqgIR2Sk9/PDD9O/fnz59+vCzn/2M8vLypLdKf/LJJ5k5cyZnn312tZXLlClT6NOnDwcddBCX\nXHLJlnWvueaaLbdav/baawEYP348Bx54IL179+boo4/OyM+croxWIO5eamaXA5OBPGCsu882s5HA\ndHefCFxuZoOAb4GvgAuibWeb2QRgDlAKXObuDVciqAIRyYwcup/7Rx99xDPPPMPbb79Nfn4+w4cP\nZ/z48fTo0WObW6W3bt2au+++mz//+c/06dMn9j03bNjAsGHDeP311+nRowfnnnsuY8aM4ayzzmLS\npEnMnj0bM9tyq/Wbb76Z1157jd13373eb79e3zLeB+Luk9x9X3fv4e7/L5p3Q5Q8cPefu3svd+/j\n7ke7++yEbf9ftN1+7v58gwaqCkRkp/PSSy8xbdo0ioqK6NOnD6+//joLFiyIvVV6TXz88cfsu+++\n9OjRA4Dzzz+fN954g7Zt29KoUSMuueQSnnnmmS13AR44cCDnn38+DzzwAOXl5Q3yc9YXfRM9jioQ\nkczIofu5uzvDhg3jlltu2WZZslul10Xjxo2ZPn06L774Ik899RT33nsvU6ZM4S9/+Qvvvvsuzz33\nHP369eP999+nTZs2ddpXQ8nJq7BygioQkZ3OoEGDmDBhAitXrgTC1VpffPFF0lulA7Rs2ZK1a9em\nfM8DDjiAefPmsXDhQiAMR3vkkUeydu1a1qxZwymnnMKdd97J+++/D8DChQs55JBDuOWWW2jTpg2L\nFjXctUJ1pQokTn6+EojITuaggw7ixhtvZNCgQZSXl9O4cWPuu+8+8vLytrlVOsCFF17IxRdfTLNm\nzZg6depWA0tVaN68OX/96185/fTTKSsrY8CAAVxyySUsX76c008/nU2bNlFeXs4dd9wBwC9/+Us+\n++wz3J3jjjuOAw88MKPHoDZ0O/c4AwdCs2bw0kv1G5SI6HbuOaQut3NXE1YcVSAiIikpgcTJy1Mn\nuohICkogcVSBiDSoHbn5fHtR19+BEkgcVSAiDaagoICSkhIlkSxyd0pKSigoKEj7PXQVVhxVICIN\npnPnzhQXF7NixYpsh7JTKygooHPnzmlvrwQSRxWISINp3Lgx3bt3z3YYUkdqwoqjCkREJCUlkDi6\nlYmISEpKIHF0KxMRkZSUQOKoAhERSUkJJI4qEBGRlJRA4qgCERFJSQkkjioQEZGUlEDiqAIREUlJ\nCSSOKhARkZSUQOKoAhERSUkJJI4qEBGRlDKeQMzsBDOba2bzzWxEkuVXmdkcM/vQzF42s64Jy8rM\nbGb0mNiggaoCERFJKaM3UzSzPGA08H2gGJhmZhPdfU7Cau8DRe6+wcx+CtwOnB0t2+jufTISrCoQ\nEZGUMl2B9Afmu/tCd98MjAcGJ67g7q+6+4Zo8h0g/XsN10V+lFvLy7OyexGRXJfpBNIJ+DJhujia\nF+ci4PmE6QIzm25m75jZaQ0R4BZ5eeFZVYiISFI5Ox6ImQ0FioAjE2Z3dfdFZrY38IqZzXL3BVW2\nGw4MB+jSpUv6AVRUIOoHERFJKtMVyCJgr4TpztG8rZjZIOC3wKnuvqlivrsvip4XAq8Bfatu6+5j\n3L3I3Ys6dOiQfqSqQEREUsp0ApkG9DSz7mbWBBgCbHU1lZn1Be4nJI/lCfPbmFnT6HV7YCCQ2Ple\nv1SBiIiklNEmLHcvNbPLgclAHjDW3Web2UhgurtPBP4HaAE8ZWYAX7j7qcABwP1mVk5IfKOqXL1V\nv1SBiIiklPE+EHefBEyqMu+GhNeDYrZ7GzioYaNLoApERCQlfRM9jioQEZGUlEDiqAIREUlJCSSO\nKhARkZSUQOKoAhERSUkJJI4qEBGRlJRA4qgCERFJSQkkjioQEZGUlEDiqAIREUlJCSSOKhARkZSU\nQOKoAhERSUkJJI4qEBGRlJRA4qgCERFJSQkkjioQEZGUlEDiqAIREUlJCSSOKhARkZSUQOKoAhER\nSUkJJI4qEBGRlJRA4qgCERFJSQkkjioQEZGUlEDiqAIREUlJCSSOKhARkZSUQOKoAhERSSnjCcTM\nTjCzuWY238xGJFl+lZnNMbMPzexlM+uasOwCM5sXPS5o0EBVgYiIpJTRBGJmecBo4ESgEPiRmRVW\nWe19oMjdvwP8Dbg92rYtcCMwAOgP3GhmbRosWFUgIiIpZboC6Q/Md/eF7r4ZGA8MTlzB3V919w3R\n5DtA5+j18cCL7r7K3b8CXgROaLBIVYGIiKSU6QTSCfgyYbo4mhfnIuD52mxrZsPNbLqZTV+xYkX6\nkaoCERFJKWc70c1sKFAE/E9ttnP3Me5e5O5FHTp0SD8AVSAiIillOoEsAvZKmO4czduKmQ0Cfguc\n6u6barNtvamoQJRARESSynQCmQb0NLPuZtYEGAJMTFzBzPoC9xOSx/KERZOB48ysTdR5flw0r2FU\nVCBqwhIRSSo/kztz91Izu5xw4s8Dxrr7bDMbCUx394mEJqsWwFNmBvCFu5/q7qvM7BZCEgIY6e6r\nGixYNWGJiKSU0QQC4O6TgElV5t2Q8HpQim3HAmMbLroEZtCokSoQEZEYOduJnhPy81WBiIjEUAJJ\nJS9PFYiISAwlkFRUgYiIxFICSUUViIhIrDonEDMrNLMzzGzP+ggop6gCERGJVasEYmZ/NrP7EqZP\nBz4AngLmmNl36zm+7FIFIiISq7YVyInA2wnTNwPPAb2BqYS75e44VIGIiMSqbQLZA/gcwMw6A72A\nW919FvAnQBWIiMhOorYJZAPhW+IARwJrgOnR9DqgZT3FlRtUgYiIxKrtN9FnAJeZ2RfAZYTxOcqj\nZd2BJfUZXNapAhERiVXbBPJb4AVCx/nXwKUJy04j9IPsOFSBiIjEqlUCcfdpZtYF2B+Y5+5rEhaP\nAebVZ3BZl5+vCkREJEatb6bo7uuB9xLnmVk7d/+/eosqV+TlqQIREYlR2++BXGJm1yRMH2RmxcDy\naBjZjvUeYTapAhERiVXbq7CuADYmTN9B6Av5BdAKGFlPceUGVSAiIrFq24TVFfgEwMxaES7lPc3d\nJ5lZCXBrPceXXapARERi1bYCaQRUXLZ7GODAa9H0l8Bu9RNWjlAFIiISq7YJZB5wcvR6CPC2u2+I\npvcEGm6I2WxQBSIiEqu2TVj/CzxqZhcAbYCzEpYdDXxYX4HlBFUgIiKxavs9kMejb6EPAKa5+xsJ\ni5cBE+szuKxTBSIiEiud74G8BbyVZP6OdSdeUAUiIpJCrROImTUHhhGuwGpL6Pd4FXjQ3Tem2na7\nowpERCRWbb9I2JFwQ8U/AUVA8+j5z8AMM9u9Bu9xgpnNNbP5ZjYiyfIjzGyGmZWa2ZlVlpWZ2czo\n0fDNZapARERi1fYqrNsJneeHu3t3dz/U3bsTLultDdyWamMzywNGEwamKgR+ZGaFVVb7Avgx8HiS\nt9jo7n2ix6m1jL32VIGIiMRKZ0TC69z9X4kz3f1t4HoqL/GN0x+Y7+4L3X0zMB4YXOW9Pnf3D6n8\nvkn2qAIREYlV2wTSAlgcs6yYysGm4nQifOEwcZtOtdh/QXTPrXfM7LRkK5jZ8Gid6StWrKjFWyeh\nCkREJFZtE8hc4LyYZUOJbnPSgLq6exFwDnCXmfWouoK7j3H3Incv6tChQ932pgpERCRWOl8kfCTq\nLH+cMAJhR8K30gcRn1wqLAL2SpjuHM2rEXdfFD0vNLPXgL7AgppuX2uqQEREYtX2i4SPRZfxjgQe\nSFi0DPiJuyfr+E40DehpZt0JiWMIoZqolpm1ATa4+yYzaw8MJHTqNxxVICIisWrbhIW7jyHc96oX\ncHj03An43MxS3srE3UuBy4HJwMfABHefbWYjzexUADP7bjTGyFnA/WY2O9r8AGC6mX1A+N7JKHef\nU9v4a0UViIhIrFp/kRDA3csJCWCL6PbuvWqw7SRgUpV5NyS8nkZo2qq63dvAQenEmzZVICIisWpd\ngexUmjaFb77JdhQiIjlJCSSVXXeFzZvDQ0REtqIEkkRJCfTtCzPmtQwz1q7NbkAiIjmo2j4QM9u7\nhu/VsY6x5IxGjWDmTCg5IEoga9ZAu3bZDUpEJMfUpBN9PmHo2upYDdfLeU2bhuf1jVSBiIjEqUkC\nubDBo8gxFQlkre0avVACERGpqtoE4u4PZyKQXJKXB40bwzpTBSIiEked6DEKCmAtCX0gIiKyFSWQ\nGAUFsMZVgYiIxFECiVFQAF+Xqw9ERCSOEkiMpk3h6zJVICIicZRAYhQUwIbN+VFblvpARESqUgKJ\nUVAQ3QarZUtVICIiSSiBxCgogE2bCPfDUgIREdmGEkgMVSAiIqkpgcTYKoGoD0REZBtKIDFUgYiI\npKYEEmPLWFLqAxERSUoJJMaWTnRVICIiSSmBxFATlohIakogMbZKIOvXQ1lZtkMSEckpGU8gZnaC\nmc01s/lmNiLJ8iPMbIaZlZrZmVWWXWBm86LHBQ0Z55YEsmt0P6x16xpydyIi252MJhAzywNGAycC\nhcCPzKywympfAD8GHq+ybVvgRmAA0B+40czaNFSsBQWh6ChrrvthiYgkk+kKpD8w390XuvtmYDww\nOHEFd//c3T8EyqtsezzworuvcvevgBeBExoq0IpRCb8tUAIREUkm0wmkE/BlwnRxNK+ht621goLw\nvLmpBpUSEUlmh+tEN7PhZjbdzKavWLEi7fepSCCbmqgCERFJJtMJZBGwV8J052hevW3r7mPcvcjd\nizp06JB2oBUJ5JsmGlRKRCSZTCeQaUBPM+tuZk2AIcDEGm47GTjOzNpEnefHRfMaREUC2ZivCkRE\nJJmMJhB3LwUuJ5z4PwYmuPtsMxtpZqcCmNl3zawYOAu438xmR9uuAm4hJKFpwMhoXoPYJoGoD0RE\nZCv5md6hu08CJlWZd0PC62mE5qlk244FxjZogJGKq7DW50VNWKsaLFeJiGyXdrhO9PqypQ+EAth7\nb/joo+wGJCKSY5RAYmxJIN8AffrA++9nNR4RkVyjBBJjqwTSty/Mn69+EBGRBEogMbZJIAAffJC1\neEREco0SSIykCWTmzKzFIyKSa5RAYmyVQPbYA3bbTf0gIiIJlEBiVFzGu2kTYBaqkLfegnvugS++\nyGpsIiK5QAkkxlYVCMB3vwvz5sFll8H//m/W4hIRyRVKIDGaNAnPWxLINdfACy/AAQfAggVZi0tE\nJFcogcQwSxiVEMLIhMcfD/vvD599ltXYRERygRJIClslkAp77x0SSHnV8a5ERHYuSiApJE0g3buH\nmUuXZiUmEZFcoQSSQtOm0VVYifbeOzyrGUtEdnJKICnENmEBLFyY8XhERHKJEkgKSRNI167hWQlE\nRHZySiApJE0gBQXQqZOasERkp6cEkkLSBAKhI10ViIjs5JRAUohNIHvvrQQiIjs9JZAUCgqSXIUF\nIYEsXgwbN2Y8JhGRXKEEkkLTpjEVSN++4A5Tp2Y8JhGRXKEEkkJsE9YRR0CjRvDKKxmPSUQkVyiB\npBCbQFq3hoMPVgJpSM8/D88+m+0oRCSF/Ezv0MxOAP4I5AEPuPuoKsubAo8ABwMlwNnu/rmZdQM+\nBuZGq77j7pc2ZKwFBSm6OY49NtzWff162GWXhgxj51NeDsOHw9q1oa+pefPKZRs3wrp10KFD9uIT\nyYZvv4UNG8I5J/ERN2+33eCSSxo0pIwmEDPLA0YD3weKgWlmNtHd5ySsdhHwlbvvY2ZDgNuAs6Nl\nC9y9T6bibdcOVq8OVUjF+CBbHHMMjBoFb74JJ5yQqZB2Du++C8XF4fVTT8EFF1QuGzYMpk8PY7OI\n5JKysvABp7oTfHXTcfO//bZ28QwYsGMlEKA/MN/dFwKY2XhgMJCYQAYDN0Wv/wb82cwsk0FWqPjS\n+ZdfQs+eVRYOHBgGDZkyZesE4g7XXReGwf35zzMW6w5lwoRwbDt3hvvvr0wgCxbAk0+GY/z116Ep\nUaSmysoqT8q1fa7JyT9pe3cKZqH1ouLRvHnl67Ztt51X2+mKQY0aUKYTSCfgy4TpYmBA3DruXmpm\nq4F20bLuZvY+sAa43t3frLoDMxsODAfo0qVLnYKtSCBffJEkgTRvHsYHeeIJuP12yI8O5V//Crfd\nFn6Bw4ZBy5Z1imGnU14eqo4TTwwXK/zqVzBrFhx0ENxxR0geAHPmwPe+l91Ypf64w+bN6Z/ga/Kc\n9Jr8ajRrtu1JepddYPfdk89PNi9uftOmIYlsxzLeB1IHS4Au7l5iZgcDz5pZL3dfk7iSu48BxgAU\nFRV5XXZYkUD+85+YFS66CP75T5g0CU49Ff7971B17LcfzJ0bPi1ffHFdQtj5vPYaLFoUkvDxx4dq\n7i9/geuvhwcfhKOPhldfVQLJtPLy0DzTkCf4srLaxdSo0bYn6IrnNm2Sz6/Nc7NmYR8SK9MJZBGw\nV8J052hesnWKzSwfaAWUuLsDmwDc/T0zWwDsC0xvqGA7dw5/P7EJ5KSTwieR0aNDwrj++rDRK6/A\n978fTnxKILXz+9+HY3r66eEf+Mwz4dFHw6fTTZvCsT744JBApFLFCb4mHazpnODT+dJs06bJT8yt\nWoUm3rqe4Js02e4/wW/vMp1ApgE9zaw7IVEMAc6pss5E4ALg38CZwCvu7mbWAVjl7mVmtjfQE2jQ\n+4k0bgx77pkigTRuHNrnb7+9si9k3LjQfnnJJfDLX8Ls2dCrV/U7c8/8P8P69fDDH8L558PZZ1e/\nfk394x8wfjzcd184WaTyxhshUXz3u6GCe/nlcHVbs2Zh+fDh8PjjoS9k2LAwJv0BB2zfCWTz5nAl\n2dq11T/WrQuP6hJCbU/wZuEknOzEnNg8k+5zs2aVzbqyw8robzjq07gcmEy4jHesu882s5HAdHef\nCPwVeNTM5gOrCEkG4AhgpJl9C5QDl7r7qoaOuWvXFAkE4NproWNHGDQIDjywMgmcfnpIIC+/nDqB\nbNoUks306fCvf4XSOxPc4ac/Dc1vq1bVLIFs2hQ+VaZSXh76LRYsCPcLmzIlPomsXQsnnxxOiued\nF65oa9cOLk24OvuII0KT4GefwY03hnmFhfD66zX7OeuLe7gkb+XKcLzWrKk8wdckESQ+Nm+u2T4b\nNw59aFXbztu3hy5dqm9jTzVyX3NYAAASz0lEQVSvWTN9epc6y/hHBHefBEyqMu+GhNffAGcl2e5p\n4OkGD7CKrl3DB+NYbduGRFFVly7h8eabcOWVybfdtClULa+9Bnl5cPnloYLJhCefDE1DPXvCO++E\nfodOneLXf+cdOOywUAX84Q/xFwc8/3xIHhdfDA89FI7N2LFh2ZdfwsMPh1vBHHtsqCzWrQtNgY88\nAv37hyaqxO/VmIW+j+XLw/GEkJAfeyycxNesgZEj4Uc/Cv0jAJ98EiqUU0+t/lPw+vWwZEn4+Rcv\n3vqxbBmsWBGSxsqVUFqa+r0aNQrHpepjt922ndeiRfJ1Ex/VJWuRLFONWY2uXcNVpWVl4RxfK0cc\nET6BxzVPjRoVksdDD4WT63//dzghHnVUaBpr337bbcrLw/ulCqbiSqWq+1y8GObPD3E9/HC4KeSz\nz4YT8jPPhAQWZ9y48H4PPBA+/T//fOXojInuvju0+91zT6g87rgjXFjQuzeMGBGSBoR+jE2bwvzn\nngsn58aNk+/70EO3ni4sDM/XXRfiWr06XA33wAPw9NPwt7+FY3DIIXDFFeFYLVu2bYJYvDhsW1XF\nmC8dO8I++4T36dAh/D46dAgfGpKd8PWpXnY27r7DPg4++GCvq/vucwf3L79MY+P77w8bz5277bKP\nPnJv3Nj9nHPC9Lfful9xhXvPnmGbggL3c891f/31ym3Ky93793dv0cL91FPdv/46+X7POy+8z9Sp\n7jNnus+aFeafcop7Xp77J5+4N2niftVVYX5hoftRR8X/HOXl7p07uw8eHOJp29a9Qwf3OXO2Xu9v\nfwux33JLmF61yr1NG/djjnGfNy/s+4or3MeNC/sH93vuqf44VjVvXtgW3I891v3NN927dAnTu+7q\nft117mPHurduXbkehOPdtav7oYe6n3FGiOXWW90fftj9xRfdZ892/+qr8POK7MQIXQrVnmOzfpJv\nyEd9JJDnnw9H6a230th4zpyw8QMPbD1/2TL3ffd1b9fOffnybbf76CP3Sy8NJ8BGjdw//jjMf//9\n8H5HHRWe77yzcpulS92XLHGfMqUyAVWcOJs1c580qXK6b9/w/OqrYdsbbgj7mT07+c8xdWpY/6GH\nwvQnn4QEUljovm6d+8aN7k8+Gfb5ve+F6Qr33BO2bds2nMArMvGLL7oPGeK+Zk2tD6uXl4f3fe21\nynnz5rnffXdIABXWrg3HbtYs9xUr3MvKar8vkZ2QEkg9JZCKHDBuXBobl5e7t2/v/p3vuF9+eTiZ\nFReHE3izZuGTcypLl4aT7pVXhulf/SpMl5S4H3KI+/77hxPmsGFhfn5+2N8++7gvXux+003hRNuy\nZVjWtKn7wIHhB2rTxn3z5vC+y5eHZPa97yU/yf7616F6KCmpnDdliruZe6dOlclq332TJ8R77w3b\nDxuWxkEUkUxTAqmnBLJ+fThKN92U5hv88pfurVqFk2xBQThxN28eKoKaOOec0CyzerX7HnuEZiR3\n9wcfDIH16BGSxxVXuP/sZ2HdyZO3fo+KdriLLgrLoLLprMLDD4f5l13m/tln7u++637bbe4DBoT5\nJ520bWwPPOB+8snhZ3zhBfdNm+J/jgULtq5MRCRnKYHUUwJxd+/d2/3oo+v4JosXu592mvthhyXv\nE4nzr3+FX1NhYXh+6qkwf/36kJjy8tz//vfU71FW5v7YY+4rV4bXI0a4z5ix9Trl5e4XXxyqisR+\ng9693e+4I76/RUR2ODVNIBbW3TEVFRX59Ol1/6L6r34Ff/4zfPXV1ncWzwj3cInqggXheyb33Vd5\neeeUKeEKo2OPrb/9ffIJvPACdOsWvtyX6tJeEdkhmdl77l5U7XpKINV7/vnwVYUpU8IdSkREdmQ1\nTSC6U1gNHH54+D7ayy9nOxIRkdyhBFIDLVqE75L93//Bhx+G7/KJiOzslEBq6OST4aOPwhenb7ih\n+vVFRHZ0SiA19Otfh/sdHn54uIWUqhAR2dkpgdRQo0bh9k2XXBJGKHznnWxHJCKSXUogtTR4cLiK\ndvz4bEciIpJdSiC1tOuuoT9kwoQwjIWIyM5KCSQNl18ehqe48EL1hYjIzksJJA1HHw233RaqkJtv\nznY0IiLZoQGl0nT11fDxx2EwvP33D3cbASgpCeMtdesG/fplNUQRkQalCiRNZuG2VIcfDuecA3vs\nEUYubd8ezjgDiorCaK7ffpvtSEVEGoYqkDpo0gT+8Q/4y19g7txwu5Pu3eF73wtDjt91V+h0VzOX\niOyIlEDqqE2b8CXDqo44Atauhd//Plz6q+YsEdnRqAmrAf3xj9ChQ0ggyW4KvHYtvP02vPlmuFu7\niMj2JOMViJmdAPwRyAMecPdRVZY3BR4BDgZKgLPd/fNo2XXARUAZcKW7T85g6LXWpk24AeNpp4Vm\nrX79oHHjMOTGpk2wbl0Y7qPCAQfAfvuFpFNUBAMGQK9eoWls/nz44AMYNAhatUq93yVLQnLad19Y\ntQrKysJ7bi/c4e67w/PPf57taEQkTkYTiJnlAaOB7wPFwDQzm+jucxJWuwj4yt33MbMhwG3A2WZW\nCAwBegF7Ai+Z2b7uXpbJn6G2+vaF994LTVnvvw+lpXD66bDLLtC6dVjerFm4ouuf/wyVyBtvhH4V\nCAmndWtYsSJMN2sWOurXroWhQ8NYUiUlMGMGrFkTvpfy1FOh837ffWHhwjDm1KhRYf1WrcKyzZsr\nH82bh3hWrQon7by88CXJFi3CvgAWLYJPP4Xdd4euXcOyCqWlYZtXXoE//AF69gwXEuy/f3ifFSvC\nflq1Cu+Xnw8tW1aOi1Vh9Wr47DO4//5wgQKEdcvLQx9T9+7Qo0f4ufbbL+wzmW++gY0bQwIXkYaT\n0QGlzOxQ4CZ3Pz6avg7A3W9NWGdytM6/zSwfWAp0AEYkrpu4Xtz+6mtAqUxzD4nk3XfDHYBLSsIJ\ns29feOaZkCg2b4ann668yqtlS2jXLiw7++yw/qRJ0KcPzJkDzz2XXiyNGoUrzsqqpOk2bcJFBBs2\nhGSWnx8SyR57hHg3b67+vQsKwnqNG4fHunWVy66+GmbNgsmTK3++tWu33rZZs8qxd8vLK1+vXx/W\nadcO2rZN7+eG8HNvb9vuLHSMqte7NzzxRHrb1nRAqUw3YXUCvkyYLgYGxK3j7qVmthpoF81/p8q2\n24y3ambDgeEAXbp0qbfAM8kM9tknPKo65pjK10uXwuLF4ZN99+7hZJ+oovnHPYxS++mnIcE0aRIe\nTZtWnrg3bAgn27y8kJSaNw/zly0L23fsGJrYVq4MVcKXX4ak0qxZ2O6bb2DPPeHii8On/7ffDkmw\nRYtweXPjxvD11yG5lJeHauPrr0McpaWhSa9z5/Bz7LdfGL139epQOZ18Mhx2WBhSeMGCkBBnzQr7\nrEhwiY82bUKCmTdv66RTG3X5XJWtbXcWOkY10717w+9jh7sKy93HAGMgVCBZDqdBdewYHtUxgxNP\nDI9MKCgIJ/26atUKbr21crpNm9A3VFTt5yIRyYRMX4W1CNgrYbpzNC/pOlETVitCZ3pNthURkQzJ\ndAKZBvQ0s+5m1oTQKT6xyjoTgQui12cCr3joqJkIDDGzpmbWHegJTM1Q3CIiUkVGm7CiPo3LgcmE\ny3jHuvtsMxsJTHf3icBfgUfNbD6wipBkiNabAMwBSoHLcv0KLBGRHVlGr8LKtO31KiwRkWyq6VVY\n+ia6iIikRQlERETSogQiIiJpUQIREZG07NCd6Ga2AvhPHd6iPbCynsKpT4qrdnI1Lsjd2BRX7eRq\nXJBebF3dvdpbsO7QCaSuzGx6Ta5EyDTFVTu5GhfkbmyKq3ZyNS5o2NjUhCUiImlRAhERkbQogaQ2\nJtsBxFBctZOrcUHuxqa4aidX44IGjE19ICIikhZVICIikhYlEBERSYsSSBJmdoKZzTWz+WY2Iotx\n7GVmr5rZHDObbWY/j+bfZGaLzGxm9DgpS/F9bmazohimR/PamtmLZjYves7oyORmtl/CcZlpZmvM\n7BfZOGZmNtbMlpvZRwnzkh4fC/4U/c19aGb9MhzX/5jZJ9G+nzGz1tH8bma2MeG43ddQcaWILfZ3\nZ2bXRcdsrpkdn+G4nkyI6XMzmxnNz9gxS3GOyMzfmbvrkfAg3GZ+AbA30AT4ACjMUix7AP2i1y2B\nT4FC4Cbg6hw4Vp8D7avMux0YEb0eAdyW5d/lUqBrNo4ZcATQD/iouuMDnAQ8DxhwCPBuhuM6DsiP\nXt+WEFe3xPWydMyS/u6i/4UPgKZA9+j/Ni9TcVVZ/gfghkwfsxTniIz8nakC2VZ/YL67L3T3zcB4\nYHA2AnH3Je4+I3q9FviYJOPA55jBwMPR64eB07IYy7HAAnevy90I0ububxDGtEkUd3wGA4948A7Q\n2sz2yFRc7j7F3UujyXcII35mXMwxizMYGO/um9z9M2A+4f83o3GZmQE/BJ5oiH2nkuIckZG/MyWQ\nbXUCvkyYLiYHTtpm1g3oC7wbzbo8KkHHZrqZKIEDU8zsPTMbHs3b3d2XRK+XArtnJzQgDEaW+E+d\nC8cs7vjk0t/dMMKn1Ardzex9M3vdzA7PUkzJfne5cswOB5a5+7yEeRk/ZlXOERn5O1MC2Q6YWQvg\naeAX7r4GuBfoAfQBlhDK52w4zN37AScCl5nZEYkLPdTMWblO3MKQyacCT0WzcuWYbZHN4xPHzH5L\nGPFzXDRrCdDF3fsCVwGPm9muGQ4r5353VfyIrT+oZPyYJTlHbNGQf2dKINtaBOyVMN05mpcVZtaY\n8Icxzt3/DuDuy9y9zN3Lgb/QQGV7ddx9UfS8HHgmimNZRUkcPS/PRmyEpDbD3ZdFMebEMSP++GT9\n787MfgycApwbnXSImodKotfvEfoZ9s1kXCl+d7lwzPKB04EnK+Zl+pglO0eQob8zJZBtTQN6mln3\n6FPsEGBiNgKJ2lb/Cnzs7nckzE9ss/wv4KOq22Ygtl3MrGXFa0In7EeEY3VBtNoFwD8yHVtkq0+F\nuXDMInHHZyJwfnSVzCHA6oQmiAZnZicAvwZOdfcNCfM7mFle9HpvoCewMFNxRfuN+91NBIaYWVMz\n6x7FNjWTsQGDgE/cvbhiRiaPWdw5gkz9nWXiSoHt7UG4UuFTwieH32YxjsMIpeeHwMzocRLwKDAr\nmj8R2CMLse1NuALmA2B2xXEC2gEvA/OAl4C2WYhtF6AEaJUwL+PHjJDAlgDfEtqaL4o7PoSrYkZH\nf3OzgKIMxzWf0DZe8Xd2X7TuGdHvdyYwA/hBFo5Z7O8O+G10zOYCJ2Yyrmj+Q8ClVdbN2DFLcY7I\nyN+ZbmUiIiJpUROWiIikRQlERETSogQiIiJpUQIREZG0KIGIiEhalEBkp2dmPzYzj3l8neXYHjKz\n4urXFMm8/GwHIJJDziJc45+oNNmKIqIEIpJoprvPz3YQItsLNWGJ1FBCU9cRZvasma0zsxIzG21m\nzaqsu4eZPWJmK81sU3Qn2aFJ3rO7mT1qZkuj9Raa2R+TrNfXzN40sw3RIEGXVlne0cweNrPF0fss\nMbPnzGy3+j8SIoEqEJFKedHN8RKVe7iJX6LHgAnAPYQb+91AuH3Kj2HLvcFeB9oAvyHcImQo8KiZ\nNXf3MdF63Qn3btoQvcc8oAvhvmKJdgUeB+4CRgIXAvea2Vx3fzVa51HCwFnXRPvbnTAeSvN0DoRI\njTTkfW300GN7eBBO/B7zeC7JevdV2f63QBmwbzR9ebTeUVXWe4lwV9S8aPoRYB2wZ4rYHore6+iE\neU0J9/oakzBvHXBlto+lHjvXQxWISKX/YttO9GRXYU2oMj0e+B2hGvmUMPzpInd/rcp6jwEPEoYc\nnUWoNJ5z98XVxLXBKysN3H2TmX1KqFYqTAOuie7O+gphSFXd6E4alBKISKWPvGad6MtipitGdmtL\nuHNrVUsTlkO4Y2pNLtH9Ksm8TUBBwvTZwI2EW7LfBSwxs/uA3/m2TXAi9UKd6CK1V3WY3orpioF5\nVgEdk2zXMWE5wErqaQhWd1/u7pe5eydgf0LT183AT+rj/UWSUQIRqb0fVpkeApRTOV7960BnMxtY\nZb1zCH0gc6LpKcApVQZMqjN3n+vuvyFULgfW53uLJFITlkilPmbWPsn86e6e+IXCk8zsfwgJoD+h\n6egRd58XLX8I+Dnw92iM8WLgXOD7wE/cvSxa70bC4D9vm9nvCYM6dQJOcPdtLvmNY2atCB3044BP\nCIMeDSZcBTalpu8jUltKICKVnoqZ34HQ3FRhKPAr4KfAZsI43VdXLHT39WZ2JHA7MApoSRgx7zx3\nfyxhvc+jYUV/B9wKtCA0g9V2GOBvCCPfXUK4lLc82t+57p6tIYVlJ6ARCUVqyMx+TLiKqmcNO9tF\ndmjqAxERkbQogYiISFrUhCUiImlRBSIiImlRAhERkbQogYiISFqUQEREJC1KICIikpb/D4HZiUzN\naqQiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5QpLVwRyT1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "b1f746c4-2c9b-4a16-a9d4-2f99eb3ae472"
      },
      "source": [
        "plt.plot(range(len(train_loss)), train_accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(range(len(train_loss)), test_accuracy, 'r', label='Test Accuracy')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEbCAYAAAD0yNLXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78opLxUMyWx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}